{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0a61acd5-8e4e-4125-987d-950969edfecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.166.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client) (2.24.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463ac678-b101-476e-8519-9090e2406df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0a6927-06ef-45f6-9ab7-e0f7a3b45c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='AIzaSyA6ntWVM617zvwKkCdOs9a0aL4qFRGOMDo'\n",
    "\n",
    "\n",
    "# Youtubers generally famous and i prefer to watch tutorials from.(Data Domain)\n",
    "channel_ids=[#'UCnz-ZXXER4jOvuED5trXfEA',#TechTFQ\n",
    "             #'UCk7NcgnqCmui1AV7MTXZwOw',#Ankit Bansal     \n",
    "             #'UC8LUT6Qn7MSvPQPM8ZJsW8g',#LearnWidgiggs\n",
    "             #'UC8uU_wruBMHeeRma49dtZKA',#chandoo\n",
    "             #'UC3rY5HOgbBvGmq7RnDfwF7A',#Rishabh Mishra\n",
    "             #'UCNU_lfiiWBdtULKOw6X0Dig',#Krish Naik\n",
    "             #'UCD7FERT7OXNgLYkvEyy3qGQ',#Zero Analyst\n",
    "             #'UCh9nVJoWXmFb7sLApWGcLPQ',#Codebasics\n",
    "             #'UC7cs8q-gJRlGwj4A8OmCmXg',#Alex the Analyst\n",
    "             #'UCH6gDteHtH4hg3o2343iObA',#Analytics Vidhya\n",
    "             #'UCiT9RITQ9PW6BhXK0y2jaeg',#KenJee\n",
    "             #'UCFp1vaKzpfvoGai0vE5VJ0w',#Guy in a cube\n",
    "             #'UCEBpSZhI1X8WaP-kY_2LLcg',#365 Datascience\n",
    "             #'UC8butISFwT-Wl7EV0hUK0BQ',#Freecodecamp\n",
    "             #'UC79Gv3mYp6zKiSwYemEik9A',#Datacamp\n",
    "             #'UCRDhrUdd9yoVoFFQqadR4FQ',#Satish Dhawale\n",
    "    ]\n",
    "             \n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbfa79c-83e3-458c-abb5-a51df77a0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9ee7c6-3669-46cd-b581-7132b662820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiple Channels\n",
    "\n",
    "def get_channel_status(youtube, channel_ids):\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids) # we use join becoz channels.list() is designed to accept a single channel ID or a comma-separated list of channel IDs\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    if 'items' in response: \n",
    "        channel_data = {} # holds data for multiple channels\n",
    "        for item in response['items']:\n",
    "            channel_id = item['id']\n",
    "\n",
    "            iso_time = item['snippet']['publishedAt']\n",
    "            utc_time = datetime.fromisoformat(iso_time.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "            # Convert to IST\n",
    "            ist_time = utc_time.astimezone(pytz.timezone(\"Asia/Kolkata\"))\n",
    "            format_time= ist_time.strftime(\"%d-%b-%Y %I:%M %p\")\n",
    "            \n",
    "            data = {\n",
    "            'Channel Name': item['snippet']['title'],\n",
    "            'Channel ID': item['id'],\n",
    "            #'Description': item['snippet']['description'],\n",
    "             'Custom URL': item['snippet']['customUrl'],\n",
    "            'Published At': format_time,\n",
    "            'Subscribers': item['statistics'].get('subscriberCount', 0),\n",
    "            'Views': item['statistics'].get('viewCount', 0),\n",
    "            'Total Videos': item['statistics'].get('videoCount', 0),\n",
    "            'Country': item['snippet']['country'],\n",
    "             'Upload ID': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "            }\n",
    "\n",
    "            channel_data[channel_id] = data\n",
    "        return channel_data\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd170ff7-542f-42e0-8a89-2de20fdceaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_stats=get_channel_status(youtube,channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be3082f-3fc6-4483-8fbd-e8baffa85e74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'channel_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Utube_dataset \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mchannel_stats\u001b[49m)\n\u001b[0;32m      2\u001b[0m Channel_data\u001b[38;5;241m=\u001b[39mUtube_dataset\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      3\u001b[0m Channel_data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChannel URL Link\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_name\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChannel Name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubscribers\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubscribers\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviews\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mViews\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_videos\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Videos\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[0;32m      4\u001b[0m inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'channel_stats' is not defined"
     ]
    }
   ],
   "source": [
    "Utube_dataset =pd.DataFrame(channel_stats)\n",
    "Channel_data=Utube_dataset.T\n",
    "Channel_data.rename(columns={' ':'Channel URL Link','channel_name':'Channel Name','subscribers':'Subscribers','views':'Views','Total_videos':'Total Videos'},\n",
    "inplace=True)\n",
    "Channel_data.reset_index(drop=True,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bccb4061-9302-4971-a023-4f32a8b0b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Custom URL</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Subscribers</th>\n",
       "      <th>Views</th>\n",
       "      <th>Total Videos</th>\n",
       "      <th>Country</th>\n",
       "      <th>Upload ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harkirat Singh</td>\n",
       "      <td>UCWX0cUR2rZcqKei1Vstww-A</td>\n",
       "      <td>@harkirat1</td>\n",
       "      <td>30-Sep-2007 06:07 PM</td>\n",
       "      <td>541000</td>\n",
       "      <td>40754951</td>\n",
       "      <td>282</td>\n",
       "      <td>N/A</td>\n",
       "      <td>UUWX0cUR2rZcqKei1Vstww-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apna College</td>\n",
       "      <td>UCBwmMxybNva6P_5VmxjzwqA</td>\n",
       "      <td>@apnacollegeofficial</td>\n",
       "      <td>05-Aug-2020 09:39 PM</td>\n",
       "      <td>6650000</td>\n",
       "      <td>1071681939</td>\n",
       "      <td>943</td>\n",
       "      <td>N/A</td>\n",
       "      <td>UUBwmMxybNva6P_5VmxjzwqA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahil &amp; Sarra</td>\n",
       "      <td>UCkcqmxjMXaBb0kDWqqSEU1g</td>\n",
       "      <td>@sahilandsarra</td>\n",
       "      <td>13-Sep-2021 08:43 AM</td>\n",
       "      <td>824000</td>\n",
       "      <td>79469445</td>\n",
       "      <td>212</td>\n",
       "      <td>N/A</td>\n",
       "      <td>UUkcqmxjMXaBb0kDWqqSEU1g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chai aur Code</td>\n",
       "      <td>UCNQ6FEtztATuaVhZKCY28Yw</td>\n",
       "      <td>@chaiaurcode</td>\n",
       "      <td>09-Nov-2022 12:06 AM</td>\n",
       "      <td>623000</td>\n",
       "      <td>57139034</td>\n",
       "      <td>559</td>\n",
       "      <td>IN</td>\n",
       "      <td>UUNQ6FEtztATuaVhZKCY28Yw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take U forward</td>\n",
       "      <td>UCJskGeByzRRSvmOyZOz61ig</td>\n",
       "      <td>@takeuforward</td>\n",
       "      <td>16-Mar-2020 11:13 PM</td>\n",
       "      <td>816000</td>\n",
       "      <td>128621525</td>\n",
       "      <td>536</td>\n",
       "      <td>IN</td>\n",
       "      <td>UUJskGeByzRRSvmOyZOz61ig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GeeksforGeeks</td>\n",
       "      <td>UC0RhatS1pyxInC00YKjjBqQ</td>\n",
       "      <td>@geeksforgeeksvideos</td>\n",
       "      <td>11-Jun-2015 08:57 PM</td>\n",
       "      <td>1000000</td>\n",
       "      <td>157447503</td>\n",
       "      <td>3517</td>\n",
       "      <td>IN</td>\n",
       "      <td>UU0RhatS1pyxInC00YKjjBqQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CodeWithHarry</td>\n",
       "      <td>UCeVMnSShP_Iviwkknt83cww</td>\n",
       "      <td>@codewithharry</td>\n",
       "      <td>28-Apr-2018 08:20 PM</td>\n",
       "      <td>7410000</td>\n",
       "      <td>945075837</td>\n",
       "      <td>2462</td>\n",
       "      <td>IN</td>\n",
       "      <td>UUeVMnSShP_Iviwkknt83cww</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Programming with Mosh</td>\n",
       "      <td>UCWv7vMbMWH4-V0ZXdmDpPBA</td>\n",
       "      <td>@programmingwithmosh</td>\n",
       "      <td>07-Oct-2014 06:10 AM</td>\n",
       "      <td>4520000</td>\n",
       "      <td>237005582</td>\n",
       "      <td>239</td>\n",
       "      <td>US</td>\n",
       "      <td>UUWv7vMbMWH4-V0ZXdmDpPBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nishant Chahar</td>\n",
       "      <td>UCVe8CMJF4caRzuckVYV8CaQ</td>\n",
       "      <td>@nishantchahar11</td>\n",
       "      <td>08-Nov-2013 06:19 PM</td>\n",
       "      <td>502000</td>\n",
       "      <td>70546629</td>\n",
       "      <td>703</td>\n",
       "      <td>IN</td>\n",
       "      <td>UUVe8CMJF4caRzuckVYV8CaQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Love Babbar</td>\n",
       "      <td>UCQHLxxBFrbfdrk1jF0moTpw</td>\n",
       "      <td>@lovebabbar</td>\n",
       "      <td>25-Aug-2016 04:55 PM</td>\n",
       "      <td>617000</td>\n",
       "      <td>43215474</td>\n",
       "      <td>257</td>\n",
       "      <td>IN</td>\n",
       "      <td>UUQHLxxBFrbfdrk1jF0moTpw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Channel Name                Channel ID            Custom URL  \\\n",
       "0         Harkirat Singh  UCWX0cUR2rZcqKei1Vstww-A            @harkirat1   \n",
       "1           Apna College  UCBwmMxybNva6P_5VmxjzwqA  @apnacollegeofficial   \n",
       "2          Sahil & Sarra  UCkcqmxjMXaBb0kDWqqSEU1g        @sahilandsarra   \n",
       "3          Chai aur Code  UCNQ6FEtztATuaVhZKCY28Yw          @chaiaurcode   \n",
       "4         take U forward  UCJskGeByzRRSvmOyZOz61ig         @takeuforward   \n",
       "5          GeeksforGeeks  UC0RhatS1pyxInC00YKjjBqQ  @geeksforgeeksvideos   \n",
       "6          CodeWithHarry  UCeVMnSShP_Iviwkknt83cww        @codewithharry   \n",
       "7  Programming with Mosh  UCWv7vMbMWH4-V0ZXdmDpPBA  @programmingwithmosh   \n",
       "8         Nishant Chahar  UCVe8CMJF4caRzuckVYV8CaQ      @nishantchahar11   \n",
       "9            Love Babbar  UCQHLxxBFrbfdrk1jF0moTpw           @lovebabbar   \n",
       "\n",
       "           Published At  Subscribers       Views  Total Videos Country  \\\n",
       "0  30-Sep-2007 06:07 PM       541000    40754951           282     N/A   \n",
       "1  05-Aug-2020 09:39 PM      6650000  1071681939           943     N/A   \n",
       "2  13-Sep-2021 08:43 AM       824000    79469445           212     N/A   \n",
       "3  09-Nov-2022 12:06 AM       623000    57139034           559      IN   \n",
       "4  16-Mar-2020 11:13 PM       816000   128621525           536      IN   \n",
       "5  11-Jun-2015 08:57 PM      1000000   157447503          3517      IN   \n",
       "6  28-Apr-2018 08:20 PM      7410000   945075837          2462      IN   \n",
       "7  07-Oct-2014 06:10 AM      4520000   237005582           239      US   \n",
       "8  08-Nov-2013 06:19 PM       502000    70546629           703      IN   \n",
       "9  25-Aug-2016 04:55 PM       617000    43215474           257      IN   \n",
       "\n",
       "                  Upload ID  \n",
       "0  UUWX0cUR2rZcqKei1Vstww-A  \n",
       "1  UUBwmMxybNva6P_5VmxjzwqA  \n",
       "2  UUkcqmxjMXaBb0kDWqqSEU1g  \n",
       "3  UUNQ6FEtztATuaVhZKCY28Yw  \n",
       "4  UUJskGeByzRRSvmOyZOz61ig  \n",
       "5  UU0RhatS1pyxInC00YKjjBqQ  \n",
       "6  UUeVMnSShP_Iviwkknt83cww  \n",
       "7  UUWv7vMbMWH4-V0ZXdmDpPBA  \n",
       "8  UUVe8CMJF4caRzuckVYV8CaQ  \n",
       "9  UUQHLxxBFrbfdrk1jF0moTpw  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Channel_data.dtypes\n",
    "Channel_data['Subscribers'] = Channel_data['Subscribers'].astype(int)\n",
    "Channel_data['Views'] = Channel_data['Views'].astype(int)\n",
    "Channel_data['Total Videos'] = Channel_data['Total Videos'].astype(int)\n",
    "\n",
    "Channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11db69d7-dec6-44a5-a54d-6ee8e2c0c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "Channel_data.to_csv('channel_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3872eae4-4c38-4200-b4d9-30857c7dc833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter YouTube channel ID (or URL):  UC7cs8q-gJRlGwj4A8OmCmXg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching video details, please wait...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Video Link</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Engagement Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Practice for General Technical Intervie...</td>\n",
       "      <td>https://www.youtube.com/watch?v=dStNNjOKML4</td>\n",
       "      <td>06-May-2025 05:31 PM</td>\n",
       "      <td>1958</td>\n",
       "      <td>94</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Lie with Data | Biased Data Collection</td>\n",
       "      <td>https://www.youtube.com/watch?v=OQM9x6E3ojo</td>\n",
       "      <td>29-Apr-2025 05:30 PM</td>\n",
       "      <td>2407</td>\n",
       "      <td>84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Lie with Data | Correlations</td>\n",
       "      <td>https://www.youtube.com/watch?v=z39SB95JbDo</td>\n",
       "      <td>22-Apr-2025 05:31 PM</td>\n",
       "      <td>3013</td>\n",
       "      <td>124</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to Lie with Data | Cherry Picking Data</td>\n",
       "      <td>https://www.youtube.com/watch?v=W5CQb7klLCs</td>\n",
       "      <td>15-Apr-2025 05:30 PM</td>\n",
       "      <td>3457</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to Lie with Data | Averages</td>\n",
       "      <td>https://www.youtube.com/watch?v=xb5-UX-jYw0</td>\n",
       "      <td>08-Apr-2025 05:31 PM</td>\n",
       "      <td>3947</td>\n",
       "      <td>209</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Data Analyst Resume | Reviewing My Resume! | F...</td>\n",
       "      <td>https://www.youtube.com/watch?v=4rfr6A3lO-Y</td>\n",
       "      <td>30-Jan-2020 07:37 PM</td>\n",
       "      <td>80644</td>\n",
       "      <td>1745</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Working at a Big Company Vs Small Company | To...</td>\n",
       "      <td>https://www.youtube.com/watch?v=OTq2NRy_AGs</td>\n",
       "      <td>25-Jan-2020 10:08 PM</td>\n",
       "      <td>15943</td>\n",
       "      <td>425</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Data Analyst Salary | 100k with No Experience</td>\n",
       "      <td>https://www.youtube.com/watch?v=ya28cb3zFGE</td>\n",
       "      <td>23-Jan-2020 08:46 AM</td>\n",
       "      <td>66222</td>\n",
       "      <td>2238</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Truth About Big Companies | Told by a Fortune ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=Hsi2BG0SOiQ</td>\n",
       "      <td>21-Jan-2020 09:22 AM</td>\n",
       "      <td>9693</td>\n",
       "      <td>344</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Top 3 Data Analyst Skills in 2020</td>\n",
       "      <td>https://www.youtube.com/watch?v=6lQzbk6_OTw</td>\n",
       "      <td>17-Jan-2020 08:01 PM</td>\n",
       "      <td>30869</td>\n",
       "      <td>1461</td>\n",
       "      <td>142</td>\n",
       "      <td>0.0519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    How to Practice for General Technical Intervie...   \n",
       "1        How to Lie with Data | Biased Data Collection   \n",
       "2                  How to Lie with Data | Correlations   \n",
       "3           How to Lie with Data | Cherry Picking Data   \n",
       "4                      How to Lie with Data | Averages   \n",
       "..                                                 ...   \n",
       "355  Data Analyst Resume | Reviewing My Resume! | F...   \n",
       "356  Working at a Big Company Vs Small Company | To...   \n",
       "357      Data Analyst Salary | 100k with No Experience   \n",
       "358  Truth About Big Companies | Told by a Fortune ...   \n",
       "359                  Top 3 Data Analyst Skills in 2020   \n",
       "\n",
       "                                      Video Link        Published Date  Views  \\\n",
       "0    https://www.youtube.com/watch?v=dStNNjOKML4  06-May-2025 05:31 PM   1958   \n",
       "1    https://www.youtube.com/watch?v=OQM9x6E3ojo  29-Apr-2025 05:30 PM   2407   \n",
       "2    https://www.youtube.com/watch?v=z39SB95JbDo  22-Apr-2025 05:31 PM   3013   \n",
       "3    https://www.youtube.com/watch?v=W5CQb7klLCs  15-Apr-2025 05:30 PM   3457   \n",
       "4    https://www.youtube.com/watch?v=xb5-UX-jYw0  08-Apr-2025 05:31 PM   3947   \n",
       "..                                           ...                   ...    ...   \n",
       "355  https://www.youtube.com/watch?v=4rfr6A3lO-Y  30-Jan-2020 07:37 PM  80644   \n",
       "356  https://www.youtube.com/watch?v=OTq2NRy_AGs  25-Jan-2020 10:08 PM  15943   \n",
       "357  https://www.youtube.com/watch?v=ya28cb3zFGE  23-Jan-2020 08:46 AM  66222   \n",
       "358  https://www.youtube.com/watch?v=Hsi2BG0SOiQ  21-Jan-2020 09:22 AM   9693   \n",
       "359  https://www.youtube.com/watch?v=6lQzbk6_OTw  17-Jan-2020 08:01 PM  30869   \n",
       "\n",
       "     Likes  Comments  Engagement Rate  \n",
       "0       94        15           0.0557  \n",
       "1       84        10           0.0391  \n",
       "2      124        14           0.0458  \n",
       "3      149         8           0.0454  \n",
       "4      209        14           0.0565  \n",
       "..     ...       ...              ...  \n",
       "355   1745        63           0.0224  \n",
       "356    425        23           0.0281  \n",
       "357   2238       229           0.0373  \n",
       "358    344        20           0.0376  \n",
       "359   1461       142           0.0519  \n",
       "\n",
       "[360 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Video details in tabular format\n",
    "from googleapiclient.discovery import build\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# API Key\n",
    "api_key = 'AIzaSyA6ntWVM617zvwKkCdOs9a0aL4qFRGOMDo'  # Replace with your API key\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Function to get channel's Uploads Playlist ID\n",
    "\n",
    "def get_uploads_playlist_id(channel_id):\n",
    "    response = youtube.channels().list(\n",
    "        part=\"contentDetails\",\n",
    "        id=channel_id\n",
    "    ).execute()\n",
    "    \n",
    "    playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    return playlist_id\n",
    "\n",
    "# Function to get video IDs from the playlist\n",
    "def get_video_ids_from_playlist(playlist_id):\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        response = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return video_ids\n",
    "\n",
    "# Function to get video details\n",
    "def get_video_details(video_ids):\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        response = youtube.videos().list(\n",
    "            part='snippet,statistics',\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        ).execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            stats = item['statistics']\n",
    "            views = int(stats.get('viewCount', 0))\n",
    "            likes = int(stats.get('likeCount', 0))\n",
    "            comments = int(stats.get('commentCount', 0))\n",
    "            engagement_rate = ((likes + comments) / views) if views > 0 else 0  # Engagement rate\n",
    "\n",
    "            iso_time = item['snippet']['publishedAt']\n",
    "            utc_time = datetime.fromisoformat(iso_time.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "            # Convert to IST\n",
    "            ist_time = utc_time.astimezone(pytz.timezone(\"Asia/Kolkata\"))\n",
    "            format_time = ist_time.strftime(\"%d-%b-%Y %I:%M %p\")\n",
    "\n",
    "            video_data = {\n",
    "                'Title': item['snippet']['title'],\n",
    "                'Video Link': f\"https://www.youtube.com/watch?v={item['id']}\",\n",
    "                'Published Date': format_time,\n",
    "                'Views': views,\n",
    "                'Likes': likes,\n",
    "                'Comments': comments,\n",
    "                'Engagement Rate': round(engagement_rate, 4)\n",
    "            }\n",
    "            all_video_info.append(video_data)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "# User input to enter channel ID or URL\n",
    "user_input = input(\"Enter YouTube channel ID (or URL): \")\n",
    "\n",
    "# Extract Channel ID from URL (if user enters the full URL)\n",
    "if \"youtube.com\" in user_input:\n",
    "    channel_id = user_input.split('channel/')[1]  # Extract channel ID\n",
    "else:\n",
    "    channel_id = user_input  # Assuming user provides only the channel ID\n",
    "\n",
    "# Fetch the Uploads Playlist ID from the channel ID\n",
    "playlist_id = get_uploads_playlist_id(channel_id)\n",
    "\n",
    "print(\"\\nFetching video details, please wait...\")\n",
    "\n",
    "\n",
    "video_ids = get_video_ids_from_playlist(playlist_id)\n",
    "video_data = get_video_details(video_ids)\n",
    "display(video_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "53bb1527-f1e1-4690-a20d-b1cc0140ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data.to_csv('video_alex.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a55f12f8-b0b5-42e4-b9c3-46f06af84632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandasql in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.7.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandasql) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandasql) (2.2.3)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandasql) (2.0.40)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->pandasql) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->pandasql) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->pandasql) (2024.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy->pandasql) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy->pandasql) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pandasql) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08570e5-0911-479f-a91b-f36c2346d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  How I Changed Careers to Become a Data Analyst...   \n",
      "1  How to Become a Data Analyst in 2023 (Complete...   \n",
      "\n",
      "                                    Video Link        Published Date    Views  \\\n",
      "0  https://www.youtube.com/watch?v=Z2AachB309o  10-Sep-2020 06:46 PM   418084   \n",
      "1  https://www.youtube.com/watch?v=CUBfrdDwznQ  31-Jan-2023 06:00 PM  1337161   \n",
      "\n",
      "   Likes  Comments  Engagement Rate  \n",
      "0  12167      3823           0.0382  \n",
      "1  43994      1327           0.0339  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#sql query in python pandas (TOP 2 MOST ENGAGED VIDEO)\n",
    "\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "query= '''\n",
    "        SELECT * \n",
    "        FROM video_data\n",
    "        WHERE Comments >1000\n",
    "        ORDER BY \"Engagement Rate\" DESC\n",
    "        LIMIT 2\n",
    "        '''\n",
    "\n",
    "result=sqldf(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c244b91-194f-4df1-9363-47f6805b10a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter YouTube video link:  https://www.youtube.com/watch?v=Z2AachB309o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching comments with sentiment, please wait...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AlexTheAnalyst</td>\n",
       "      <td>All my Jalapeño people are going to make it! 👍...</td>\n",
       "      <td>10-Sep-2020 09:17 PM</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@viralshort_films</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>04-May-2025 02:01 AM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jorgeinga4695</td>\n",
       "      <td>Jalapeño</td>\n",
       "      <td>18-Apr-2025 08:43 AM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@andreb.1529</td>\n",
       "      <td>Jalapeños !</td>\n",
       "      <td>15-Apr-2025 07:29 PM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@laleBonnaBomm</td>\n",
       "      <td>🌶</td>\n",
       "      <td>11-Mar-2025 09:04 AM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>@nobelkar7851</td>\n",
       "      <td>I like your pain</td>\n",
       "      <td>10-Sep-2020 07:52 PM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>@easy_lina</td>\n",
       "      <td>This is a great story! Thank you for sharing y...</td>\n",
       "      <td>10-Sep-2020 07:41 PM</td>\n",
       "      <td>0.528</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>@lefteris20</td>\n",
       "      <td>40 minutes video! great! greetings from greece</td>\n",
       "      <td>10-Sep-2020 07:22 PM</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>@JW-pu1uk</td>\n",
       "      <td>I appreciate you dropping the bit around 25:25...</td>\n",
       "      <td>10-Sep-2020 07:01 PM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>@pjavali29</td>\n",
       "      <td>Was waiting for a video on this topic  , thank...</td>\n",
       "      <td>10-Sep-2020 06:50 PM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2772 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Author                                            Comment  \\\n",
       "0       @AlexTheAnalyst  All my Jalapeño people are going to make it! 👍...   \n",
       "1     @viralshort_films                                          Thank you   \n",
       "2        @jorgeinga4695                                           Jalapeño   \n",
       "3          @andreb.1529                                        Jalapeños !   \n",
       "4        @laleBonnaBomm                                                  🌶   \n",
       "...                 ...                                                ...   \n",
       "2767      @nobelkar7851                                   I like your pain   \n",
       "2768         @easy_lina  This is a great story! Thank you for sharing y...   \n",
       "2769        @lefteris20     40 minutes video! great! greetings from greece   \n",
       "2770          @JW-pu1uk  I appreciate you dropping the bit around 25:25...   \n",
       "2771         @pjavali29  Was waiting for a video on this topic  , thank...   \n",
       "\n",
       "              Published At  Polarity Sentiment  \n",
       "0     10-Sep-2020 09:17 PM    -0.312  Negative  \n",
       "1     04-May-2025 02:01 AM     0.000   Neutral  \n",
       "2     18-Apr-2025 08:43 AM     0.000   Neutral  \n",
       "3     15-Apr-2025 07:29 PM     0.000   Neutral  \n",
       "4     11-Mar-2025 09:04 AM     0.000   Neutral  \n",
       "...                    ...       ...       ...  \n",
       "2767  10-Sep-2020 07:52 PM     0.000   Neutral  \n",
       "2768  10-Sep-2020 07:41 PM     0.528  Positive  \n",
       "2769  10-Sep-2020 07:22 PM     1.000  Positive  \n",
       "2770  10-Sep-2020 07:01 PM     0.000   Neutral  \n",
       "2771  10-Sep-2020 06:50 PM     0.000   Neutral  \n",
       "\n",
       "[2772 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To get Comment details\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from textblob import TextBlob  # For sentiment analysis\n",
    "\n",
    "# Initialize API key\n",
    "api_key = 'AIzaSyA6ntWVM617zvwKkCdOs9a0aL4qFRGOMDo'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Function to extract video ID\n",
    "def extract_video_id(url):\n",
    "    match = re.search(r\"(?:v=|youtu\\.be/)([a-zA-Z0-9_-]{11})\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(comment):\n",
    "    blob = TextBlob(comment)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        sentiment = \"Positive\"\n",
    "    elif polarity < -0.1:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "    return polarity, sentiment\n",
    "\n",
    "# Function to fetch comments \n",
    "def get_video_comments(video_id):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            textFormat='plainText',\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment_data = item['snippet']['topLevelComment']['snippet']\n",
    "            text = comment_data['textDisplay']\n",
    "\n",
    "            # Time conversion to IST\n",
    "            iso_time = comment_data['publishedAt']\n",
    "            utc_time = datetime.fromisoformat(iso_time.replace(\"Z\", \"+00:00\"))\n",
    "            ist_time = utc_time.astimezone(pytz.timezone(\"Asia/Kolkata\"))\n",
    "            format_time = ist_time.strftime(\"%d-%b-%Y %I:%M %p\") # to get time and dates in proper format\n",
    "\n",
    "            # For polarity and sentiment\n",
    "            polarity, sentiment = get_sentiment(text)\n",
    "\n",
    "            comments.append({\n",
    "                'Author': comment_data['authorDisplayName'],\n",
    "                'Comment': text,\n",
    "                'Published At': format_time,\n",
    "                'Polarity': round(polarity, 3),\n",
    "                'Sentiment': sentiment\n",
    "            })\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(comments)\n",
    "\n",
    "\n",
    "video_link = input(\"Enter YouTube video link: \")\n",
    "video_id = extract_video_id(video_link)\n",
    "\n",
    "if video_id:\n",
    "    print(\"\\nFetching comments with sentiment, please wait...\")\n",
    "    comments_data = get_video_comments(video_id)\n",
    "    if not comments_data.empty:\n",
    "        display(comments_data)\n",
    "    \n",
    "    else:\n",
    "        print(\"No comments found.\")\n",
    "else:\n",
    "    print(\"Invalid YouTube video link.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09beccb-3093-4674-8354-9bb2df962e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments_data.to_csv('comments_alex.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cf2bee19-8da9-4c71-8ea6-db89b3433635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushkar\\comments1_satish.csv\n"
     ]
    }
   ],
   "source": [
    "# To get file path saved by above code\n",
    "import os\n",
    "file_name = \"comments1_satish.csv\"\n",
    "full_path = os.path.abspath(file_name)\n",
    "print(full_path)\n",
    "\n",
    "# Go to powerbi> Get Data> More> others> Python Script> Write below code with path from above and \"r\"\n",
    "\n",
    "#import pandas as pd\n",
    "#comments1_alex = pd.read_csv(r\"C:\\Users\\pushkar\\comments2_alex.csv\")\n",
    "#comments1_alex\n",
    "\n",
    "#comments2_alex = pd.read_csv(r\"C:\\Users\\pushkar\\comments2_alex.csv\")\n",
    "#comments2_alex\n",
    "\n",
    "#video_alex = pd.read_csv(r\"C:\\Users\\pushkar\\video_alex.csv\")\n",
    "#video_alex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f252e89f-b1ec-45a1-9d43-e6cc700c13b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Collecting joblib (from nltk>=3.9->textblob)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pushkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 624.3/624.3 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Installing collected packages: joblib, nltk, textblob\n",
      "Successfully installed joblib-1.5.0 nltk-3.9.1 textblob-0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be88ca5-8f6e-4cb5-acd0-13352d833c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
